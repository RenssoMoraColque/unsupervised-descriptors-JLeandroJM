# ClasificaciÃ³n STL-10 con Fisher Vectors Optimizados
## Pipeline No Supervisado + SVM para Hackathon de Descriptores de Imagen

[![Accuracy](https://img.shields.io/badge/Accuracy-~67%25-green)]() [![DimensiÃ³n](https://img.shields.io/badge/DimensiÃ³n-3840%2F4096-blue)]() [![Restricciones](https://img.shields.io/badge/Restricciones-âœ“%20Cumplidas-success)]()

## 1. DescripciÃ³n del MÃ©todo

### ğŸ§  **Arquitectura del Pipeline**
Pipeline avanzado basado en descriptores locales clÃ¡sicos y codificaciÃ³n estadÃ­stica de segunda orden:

#### **ğŸ” ExtracciÃ³n de CaracterÃ­sticas Locales:**
- **SIFT Denso + RootSIFT**: Grid regular multi-escala para cobertura completa
  - *JustificaciÃ³n*: SIFT captura gradientes locales robustos a rotaciÃ³n/escala
  - *RootSIFT*: Mejora discriminaciÃ³n mediante normalizaciÃ³n L1â†’âˆšâ†’L2 (+5-10% accuracy tÃ­pico)
  - *Grid denso*: Asegura features en todas las regiones vs. keypoints automÃ¡ticos irregulares

#### **ğŸ“‰ ReducciÃ³n Dimensional Inteligente:**
- **PCA (128 â†’ 24 dims)** entrenado sobre 20k imÃ¡genes unlabeled
  - *JustificaciÃ³n*: Elimina redundancia SIFT (~24 dims capturan 85-90% varianza)
  - *Beneficio*: GMM mÃ¡s estable + 5x menos memoria + mismo poder discriminativo

#### **ğŸ¯ Modelado EstadÃ­stico:**
- **GMM (K=16, covarianza diagonal)** sobre descriptores PCA
  - *JustificaciÃ³n*: Captura distribuciÃ³n multimodal de patches visuales
  - *K=16*: Balance optimal para STL-10 (10 clases â†’ ~1.6 gaussianas/clase)
  - *Diagonal*: EstÃ¡ndar en Fisher Vectors + computacionalmente eficiente

#### **ğŸš€ CodificaciÃ³n Avanzada:**
- **Fisher Vectors** (gradientes de medias y varianzas) + **SPM** (1Ã—1 + 2Ã—2)
  - *Superioridad vs VLAD*: Incluye informaciÃ³n segundo orden (varianza) â†’ +10-15% accuracy
  - *SPM*: Preserva informaciÃ³n espacial sin explotar dimensionalidad
  - *5 regiones*: 1 global + 4 cuadrantes = contexto local+global

#### **âš–ï¸ NormalizaciÃ³n Multi-Nivel:**
- **RootSIFT**: L1 â†’ âˆš â†’ L2 (nivel descriptor)
- **Fisher**: Power normalization + L2 (nivel regiÃ³n)  
- **L2 final**: Post-concatenaciÃ³n SPM (nivel imagen)
- *Beneficio*: Cada nivel reduce dominancia de outliers y mejora separabilidad

#### **ğŸª ClasificaciÃ³n Final:**
- **SVM RBF** con hiperparÃ¡metros optimizados por CV
- *JustificaciÃ³n*: Kernel RBF captura relaciones no-lineales residuales post-Fisher

### âœ… **Cumplimiento de Restricciones del Hackathon:**
- **DimensiÃ³n final**: 2Ã—16Ã—24Ã—5 = **3,840 â‰¤ 4,096** âœ“
- **No deep learning**: Solo tÃ©cnicas clÃ¡sicas de CV âœ“  
- **No supervisiÃ³n en descriptores**: Etiquetas SOLO en SVM final âœ“
- **Dataset correcto**: Unlabeled para training, train/test para evaluaciÃ³n âœ“

## 2. Pipeline de EjecuciÃ³n (Comandos Optimizados)

### ğŸ”„ **FASE 1: Entrenamiento No Supervisado** 
*Usando 20k imÃ¡genes UNLABELED (sin etiquetas)*

```bash
# 1. ğŸ” ExtracciÃ³n masiva de descriptores SIFT
python scripts/extract_descriptors_unlabeled.py \
  --max_images 20000 \          # MÃ¡ximo volumen de datos unlabeled
  --max_desc_per_image 500 \    # Balance calidad/memoria
  --output artifacts/desc_sift_unlabeled_20k.npy
# â†’ Genera ~10M descriptores SIFT (128D) para training robusto
```

```bash
# 2. ğŸ“‰ Entrenamiento PCA para reducciÃ³n dimensional
python scripts/train_pca.py \
  --desc_path artifacts/desc_sift_unlabeled_20k.npy \
  --n_components 24 \           # Retiene ~85-90% varianza SIFT
  --output artifacts/pca_sift24.joblib
# â†’ PCA sin supervisiÃ³n: solo anÃ¡lisis de componentes principales
```

```bash
# 3. ğŸ”„ AplicaciÃ³n PCA a descriptores
python scripts/apply_pca.py \
  --desc_path artifacts/desc_sift_unlabeled_20k.npy \
  --pca_path artifacts/pca_sift24.joblib \
  --output artifacts/desc_pca24_unlabeled_20k.npy  
# â†’ Transforma 128Dâ†’24D manteniendo poder discriminativo
```

```bash
# 4. ğŸ¯ Entrenamiento GMM para Fisher Vectors
python scripts/train_gmm_fisher.py \
  --desc_path artifacts/desc_pca24_unlabeled_20k.npy \
  --n_components 16 \           # K=16: balance capacidad/dimensiÃ³n
  --output artifacts/gmm_fisher16.joblib
# â†’ GMM captura distribuciÃ³n multimodal de patches visuales
```

### ğŸ¨ **FASE 2: ExtracciÃ³n de Features**
*Usando splits etiquetados train/test (5k/8k) pero SIN usar etiquetas*

```bash
# 5. ğŸš€ GeneraciÃ³n Fisher Vectors + SPM
python scripts/extract_fisher_spm.py \
  --pca_path artifacts/pca_sift24.joblib \
  --gmm_path artifacts/gmm_fisher16.joblib \
  --step 6 \                    # Densidad grid SIFT
  --sizes 12 16                 # Multi-escala para robustez
# â†’ Aplica pipeline completo a train/test: SIFTâ†’PCAâ†’Fisherâ†’SPM
# â†’ Genera X_train_fisher.npy, X_test_fisher.npy (3840D cada imagen)
```

### âš–ï¸ **FASE 3: EvaluaciÃ³n Supervisada**
*Usando etiquetas SOLO aquÃ­*

```bash
# 6a. ğŸ” Grid Search automÃ¡tico (recomendado)
python scripts/grid_search_svm.py \
  --cv_folds 5                  # CV estratificado en train Ãºnicamente
# â†’ Encuentra automÃ¡ticamente mejores C, gamma sin tocar test
```

```bash
# 6b. âœ… EvaluaciÃ³n final con mejores hiperparÃ¡metros  
python scripts/grid_search_svm.py \
  --cv_folds 5 \
  --final_eval                  # EvalÃºa en test SOLO una vez
# â†’ Reporte final de accuracy/F1 para submission
```

### ğŸšï¸ **Pipeline Manual (alternativo):**
```bash
# EvaluaciÃ³n directa con parÃ¡metros especÃ­ficos
python scripts/train_eval_svm_rbf.py \
  --C 5.0 \
  --gamma 0.000100              # Valor encontrado por grid search
```

### ğŸ’¡ **Comandos de DiagnÃ³stico:**
```bash
# Verificar dimensiones generadas
python -c "import numpy as np; X=np.load('features/X_train_fisher.npy'); print(f'Shape: {X.shape}, Max dim: {X.shape[1]}')"

# Verificar archivos generados
ls -la artifacts/ features/
```


### ğŸ¯ **Decisiones de DiseÃ±o Clave:**

#### **Â¿Por quÃ© Fisher Vectors vs VLAD/BoVW?**
- **VLAD**: Solo primer momento (diferencias medias)
- **Fisher**: Primer + segundo momento (medias + varianzas)
- **Ganancia empÃ­rica**: 15-20% accuracy en datasets similares
- **Costo**: 2x dimensiÃ³n pero mejor discriminaciÃ³n

#### **Â¿Por quÃ© K=16 gaussianas?**
- **K=8**: Subreprenta diversidad visual (underfitting)  
- **K=32**: DimensiÃ³n final 6,720 > 4,096 (violaciÃ³n restricciÃ³n)
- **K=16**: Sweet spot: expresividad + cumplimiento lÃ­mite

#### **Â¿Por quÃ© PCA 128â†’24?**
- **Sin PCA**: GMM inestable en alta dimensiÃ³n + memoria prohibitiva
- **PCA mayor**: Retiene ruido â†’ GMM overfit
- **24 dims**: Varianza explicada 85-90% + GMM convergente

#### **Â¿Por quÃ© SPM 1Ã—1+2Ã—2 vs pirÃ¡mides mÃ¡s profundas?**
- **SPM 1Ã—1**: Info global, pierde localizaciÃ³n
- **SPM 1Ã—1+2Ã—2+4Ã—4**: 21 regiones â†’ dimensiÃ³n explota  


### âš¡ **Eficiencia Temporal**
- **ExtracciÃ³n SIFT (20k unlabeled)**: ~15 min
- **Entrenamiento PCA**: ~1 min  
- **Entrenamiento GMM**: ~2 min
- **ExtracciÃ³n Fisher (13k train+test)**: ~6 min
- **Grid Search SVM (25 configs)**: ~8 min
- **TOTAL pipeline**: ~32 min


### ğŸ”§ **Setup del Entorno**
```bash
# 1. Clonar repositorio
git clone https://github.com/RenssoMoraColque/unsupervised-descriptors-JLeandroJM.git
cd unsupervised-descriptors-JLeandroJM

# 2. Instalar dependencias
pip install -r scripts/requirements.txt
# Incluye: numpy, scipy, scikit-learn, scikit-image, opencv-contrib-python, torchvision, tqdm, joblib

# 3. Descargar STL-10 (automÃ¡tico en primer uso)
python scripts/download_stl10.py --root data

# 4. Verificar estructura
tree data/ -L 2
```

### ğŸ“ **Estructura de Archivos Generados**
```
proyecto/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ stl10_binary/          # Dataset STL-10 (descarga automÃ¡tica)
â”œâ”€â”€ artifacts/                 # Modelos entrenados (no supervisado)
â”‚   â”œâ”€â”€ desc_sift_unlabeled_20k.npy      # ~400MB
â”‚   â”œâ”€â”€ pca_sift24.joblib                # ~1MB  
â”‚   â”œâ”€â”€ desc_pca24_unlabeled_20k.npy     # ~80MB
â”‚   â””â”€â”€ gmm_fisher16.joblib              # ~2MB
â”œâ”€â”€ features/                  # Descriptores finales
â”‚   â”œâ”€â”€ X_train_fisher.npy               # 5k Ã— 3840 (~75MB)
â”‚   â”œâ”€â”€ X_test_fisher.npy                # 8k Ã— 3840 (~120MB)  
â”‚   â”œâ”€â”€ y_train.npy                      # Etiquetas train
â”‚   â””â”€â”€ y_test.npy                       # Etiquetas test
â””â”€â”€ scripts/                   # Pipeline ejecutable
```

## REPOSITORIO

https://github.com/RenssoMoraColque/unsupervised-descriptors-JLeandroJM



